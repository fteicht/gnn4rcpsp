{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpsat_sol = []\n",
    "with open('cpsat_solutions.csv', newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        cpsat_sol.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_results(cpsat_infer):\n",
    "    comparison_results = []\n",
    "    for test_bench_id, test_result in cpsat_infer.items():\n",
    "        row = 0\n",
    "        while int(cpsat_sol[row][0]) != test_result['benchmark_id']:\n",
    "            row += 1\n",
    "        bench_row_start = row\n",
    "        while int(cpsat_sol[row][3]) > test_result['feasibility_abs_makespan'] and \\\n",
    "            int(cpsat_sol[row][0]) == test_result['benchmark_id']:\n",
    "            row += 1\n",
    "        if row > bench_row_start and int(cpsat_sol[row][0]) == test_result['benchmark_id']:\n",
    "            cpsat_same_quality_time = 0.5 * (float(cpsat_sol[row - 1][1]) + float(cpsat_sol[row][1]))\n",
    "        else:\n",
    "            cpsat_same_quality_time = float(cpsat_sol[row][1])\n",
    "        infer_feasible_time = test_result['inference_time'] + test_result['feasibility_timing']\n",
    "        comparison_results.append({\n",
    "            'benchmark_id': test_result['benchmark_id'],\n",
    "            'infer_feasible_time': infer_feasible_time,\n",
    "            'cpsat_same_quality_time': cpsat_same_quality_time,\n",
    "            'rel_time_savings_per': infer_feasible_time / cpsat_same_quality_time * 100.0\n",
    "        })\n",
    "    return comparison_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unconstrained makespan case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('inference-sgs_vs_cpsat.json', 'r') as jsonfile:\n",
    "    cpsat_infer = json.load(jsonfile)\n",
    "    comparison_results = compare_results(cpsat_infer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib widget\n",
    "\n",
    "rel_time_savings_gain = [res['rel_time_savings_per'] for res in comparison_results if res['rel_time_savings_per'] < 100.]\n",
    "timings = [(res['infer_feasible_time'], res['cpsat_same_quality_time']) for res in comparison_results if res['rel_time_savings_per'] < 100.]\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize =(10, 7))\n",
    "ax1.set_xlabel('Test RCPSP benchmarks')\n",
    "ax1.set_ylabel('Relative computation time savings for same quality (%)')\n",
    "ax1.scatter(x=np.arange(len(rel_time_savings_gain)), y=rel_time_savings_gain)\n",
    "ax2.set_xlabel('Test RCPSP benchmarks')\n",
    "ax2.set_ylabel('Computation time to reach same quality (s.)')\n",
    "ax2.plot(np.arange(len(rel_time_savings_gain)), [t[0] for t in timings], label='GNN + SGS')\n",
    "ax2.plot(np.arange(len(rel_time_savings_gain)), [t[1] for t in timings], label='CP-optimize')\n",
    "ax2.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_time_savings_loss = [res['rel_time_savings_per'] for res in comparison_results if res['rel_time_savings_per'] >= 100.]\n",
    "timings = [(res['infer_feasible_time'], res['cpsat_same_quality_time']) for res in comparison_results if res['rel_time_savings_per'] >= 100.]\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize =(10, 7))\n",
    "ax1.set_xlabel('Test RCPSP benchmarks')\n",
    "ax1.set_ylabel('Relative computation time losses for same quality (%)')\n",
    "ax1.scatter(x=np.arange(len(rel_time_savings_loss)), y=rel_time_savings_loss)\n",
    "ax2.set_xlabel('Test RCPSP benchmarks')\n",
    "ax2.set_ylabel('Computation time to reach same quality (s.)')\n",
    "ax2.plot(np.arange(len(rel_time_savings_loss)), [t[0] for t in timings], label='GNN + SGS')\n",
    "ax2.plot(np.arange(len(rel_time_savings_loss)), [t[1] for t in timings], label='CP-optimize')\n",
    "ax2.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rel_time_savings_gain) / len(comparison_results) * 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rel_time_savings_loss) / len(comparison_results) * 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "ax.hist(rel_time_savings_gain + rel_time_savings_loss, bins=np.arange(start=0, stop=1000, step=10))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('rl4rcpsp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea01d3ba5ec8e0e85fa445479db093e0b138facb1ec976d469b61d1b99d76976"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
